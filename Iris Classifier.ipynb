{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "#This is the implementation of a Iris Classifier using sklearn library\n",
    "#Using python 3.7.1\n",
    "\n",
    "#Importing DS standard modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "#Importing The Datasets and Analyzinf its characteristics\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#Point the model to a variable\n",
    "iris = load_iris()\n",
    "\n",
    "#Print Dataset description\n",
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The classifications model possess three alternative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the dataset shape\n",
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spitting the model into training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4)\n",
      "(112,)\n"
     ]
    }
   ],
   "source": [
    "#Checking the training dataset shape\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Testing the classification with a Logistic Regression Module\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Pointing the model to a variable\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "#Fitting the model to training datasets\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "#Outputting scores\n",
    "print(logreg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1271842f070>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Feature Importance for Logistic Regression Model\n",
    "plt.plot(logreg.coef_.T, 'o')\n",
    "plt.xticks(range(iris.data.shape[1]), iris.feature_names, rotation=90)\n",
    "xlims = plt.xlim()\n",
    "plt.hlines(0, xlims[0], xlims[1])\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(-5, 5)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train scaled : [[0.44444444 0.41666667 0.53448276 0.58333333]\n",
      " [0.41666667 0.25       0.5        0.45833333]\n",
      " [0.69444444 0.41666667 0.75862069 0.83333333]\n",
      " [0.11111111 0.5        0.03448276 0.04166667]\n",
      " [0.72222222 0.45833333 0.68965517 0.91666667]\n",
      " [0.19444444 0.625      0.0862069  0.20833333]\n",
      " [0.30555556 0.70833333 0.06896552 0.04166667]\n",
      " [0.19444444 0.         0.4137931  0.375     ]\n",
      " [0.61111111 0.41666667 0.75862069 0.70833333]\n",
      " [0.66666667 0.54166667 0.79310345 1.        ]\n",
      " [0.47222222 0.08333333 0.67241379 0.58333333]\n",
      " [0.66666667 0.20833333 0.81034483 0.70833333]\n",
      " [0.36111111 0.20833333 0.48275862 0.41666667]\n",
      " [0.94444444 0.41666667 0.86206897 0.91666667]\n",
      " [0.55555556 0.54166667 0.62068966 0.625     ]\n",
      " [0.33333333 0.16666667 0.46551724 0.41666667]\n",
      " [0.55555556 0.29166667 0.65517241 0.70833333]\n",
      " [0.55555556 0.33333333 0.68965517 0.58333333]\n",
      " [0.16666667 0.20833333 0.5862069  0.66666667]\n",
      " [0.55555556 0.20833333 0.67241379 0.75      ]\n",
      " [0.75       0.5        0.62068966 0.54166667]\n",
      " [0.61111111 0.41666667 0.70689655 0.79166667]\n",
      " [0.47222222 0.58333333 0.5862069  0.625     ]\n",
      " [0.13888889 0.45833333 0.0862069  0.04166667]\n",
      " [0.41666667 0.29166667 0.68965517 0.75      ]\n",
      " [0.36111111 0.29166667 0.53448276 0.5       ]\n",
      " [0.36111111 0.375      0.43103448 0.5       ]\n",
      " [0.33333333 0.20833333 0.5        0.5       ]\n",
      " [0.5        0.41666667 0.60344828 0.54166667]\n",
      " [0.80555556 0.5        0.84482759 0.70833333]\n",
      " [0.27777778 0.70833333 0.06896552 0.04166667]\n",
      " [0.         0.41666667 0.         0.        ]\n",
      " [0.58333333 0.29166667 0.72413793 0.75      ]\n",
      " [0.38888889 0.41666667 0.53448276 0.45833333]\n",
      " [0.30555556 0.58333333 0.10344828 0.04166667]\n",
      " [0.38888889 1.         0.06896552 0.125     ]\n",
      " [0.72222222 0.45833333 0.65517241 0.58333333]\n",
      " [0.08333333 0.45833333 0.06896552 0.04166667]\n",
      " [0.44444444 0.41666667 0.68965517 0.70833333]\n",
      " [0.22222222 0.20833333 0.32758621 0.41666667]\n",
      " [0.08333333 0.58333333 0.05172414 0.08333333]\n",
      " [0.52777778 0.08333333 0.5862069  0.58333333]\n",
      " [0.80555556 0.66666667 0.86206897 1.        ]\n",
      " [0.38888889 0.375      0.53448276 0.5       ]\n",
      " [0.13888889 0.41666667 0.05172414 0.        ]\n",
      " [0.77777778 0.41666667 0.82758621 0.83333333]\n",
      " [0.72222222 0.5        0.79310345 0.91666667]\n",
      " [0.61111111 0.41666667 0.81034483 0.875     ]\n",
      " [0.58333333 0.33333333 0.77586207 0.83333333]\n",
      " [0.22222222 0.75       0.0862069  0.04166667]\n",
      " [0.13888889 0.58333333 0.0862069  0.04166667]\n",
      " [0.61111111 0.5        0.68965517 0.79166667]\n",
      " [0.66666667 0.54166667 0.79310345 0.83333333]\n",
      " [0.05555556 0.125      0.03448276 0.08333333]\n",
      " [0.52777778 0.58333333 0.74137931 0.91666667]\n",
      " [0.16666667 0.41666667 0.05172414 0.04166667]\n",
      " [0.38888889 0.20833333 0.67241379 0.79166667]\n",
      " [0.72222222 0.45833333 0.74137931 0.83333333]\n",
      " [0.02777778 0.5        0.03448276 0.04166667]\n",
      " [0.19444444 0.66666667 0.05172414 0.04166667]\n",
      " [0.80555556 0.41666667 0.81034483 0.625     ]\n",
      " [0.22222222 0.625      0.05172414 0.08333333]\n",
      " [0.02777778 0.41666667 0.03448276 0.04166667]\n",
      " [0.30555556 0.79166667 0.10344828 0.125     ]\n",
      " [0.33333333 0.125      0.5        0.5       ]\n",
      " [0.69444444 0.5        0.82758621 0.91666667]\n",
      " [0.91666667 0.41666667 0.94827586 0.83333333]\n",
      " [0.22222222 0.625      0.05172414 0.04166667]\n",
      " [0.16666667 0.45833333 0.06896552 0.04166667]\n",
      " [0.25       0.58333333 0.05172414 0.04166667]\n",
      " [0.38888889 0.33333333 0.5862069  0.5       ]\n",
      " [0.63888889 0.41666667 0.56896552 0.54166667]\n",
      " [0.19444444 0.5        0.01724138 0.04166667]\n",
      " [0.22222222 0.54166667 0.10344828 0.16666667]\n",
      " [0.58333333 0.375      0.55172414 0.5       ]\n",
      " [0.30555556 0.58333333 0.06896552 0.125     ]\n",
      " [0.94444444 0.25       1.         0.91666667]\n",
      " [0.16666667 0.16666667 0.37931034 0.375     ]\n",
      " [1.         0.75       0.9137931  0.79166667]\n",
      " [0.66666667 0.45833333 0.56896552 0.54166667]\n",
      " [0.25       0.875      0.06896552 0.        ]\n",
      " [0.47222222 0.41666667 0.63793103 0.70833333]\n",
      " [0.41666667 0.83333333 0.01724138 0.04166667]\n",
      " [0.94444444 0.33333333 0.96551724 0.79166667]\n",
      " [0.22222222 0.75       0.06896552 0.08333333]\n",
      " [0.11111111 0.5        0.0862069  0.04166667]\n",
      " [0.86111111 0.33333333 0.86206897 0.75      ]\n",
      " [0.19444444 0.54166667 0.05172414 0.04166667]\n",
      " [0.55555556 0.58333333 0.77586207 0.95833333]\n",
      " [0.38888889 0.33333333 0.51724138 0.5       ]\n",
      " [0.41666667 0.29166667 0.48275862 0.45833333]\n",
      " [0.38888889 0.25       0.4137931  0.375     ]\n",
      " [0.58333333 0.5        0.72413793 0.91666667]\n",
      " [0.66666667 0.41666667 0.70689655 0.91666667]\n",
      " [0.55555556 0.20833333 0.65517241 0.58333333]\n",
      " [0.66666667 0.41666667 0.67241379 0.66666667]\n",
      " [0.19444444 0.41666667 0.0862069  0.04166667]\n",
      " [0.33333333 0.16666667 0.44827586 0.375     ]\n",
      " [0.66666667 0.45833333 0.77586207 0.95833333]\n",
      " [0.41666667 0.29166667 0.68965517 0.75      ]\n",
      " [0.22222222 0.58333333 0.06896552 0.04166667]\n",
      " [0.63888889 0.375      0.60344828 0.5       ]\n",
      " [0.36111111 0.41666667 0.51724138 0.5       ]\n",
      " [0.44444444 0.5        0.63793103 0.70833333]\n",
      " [0.55555556 0.125      0.56896552 0.5       ]\n",
      " [0.33333333 0.625      0.03448276 0.04166667]\n",
      " [0.22222222 0.70833333 0.06896552 0.125     ]\n",
      " [0.16666667 0.45833333 0.06896552 0.        ]\n",
      " [0.55555556 0.375      0.77586207 0.70833333]\n",
      " [0.41666667 0.29166667 0.51724138 0.375     ]\n",
      " [0.94444444 0.75       0.96551724 0.875     ]\n",
      " [0.08333333 0.5        0.05172414 0.04166667]]\n",
      "X_test scaled: [[0.48275862 0.3        0.77358491 0.95833333]\n",
      " [0.55172414 0.         0.56603774 0.375     ]\n",
      " [0.37931034 1.         0.0754717  0.04166667]\n",
      " [1.         0.35       1.         0.70833333]\n",
      " [0.20689655 0.6        0.09433962 0.04166667]\n",
      " [0.65517241 0.55       0.94339623 1.        ]\n",
      " [0.20689655 0.65       0.05660377 0.08333333]\n",
      " [0.79310345 0.45       0.69811321 0.58333333]\n",
      " [0.82758621 0.3        0.71698113 0.54166667]\n",
      " [0.5862069  0.3        0.56603774 0.5       ]\n",
      " [0.5862069  0.2        0.86792453 0.54166667]\n",
      " [0.68965517 0.5        0.66037736 0.58333333]\n",
      " [0.5862069  0.3        0.69811321 0.45833333]\n",
      " [0.72413793 0.3        0.67924528 0.58333333]\n",
      " [0.5862069  0.35       0.69811321 0.54166667]\n",
      " [0.17241379 0.7        0.0754717  0.        ]\n",
      " [0.55172414 0.35       0.66037736 0.58333333]\n",
      " [0.37931034 0.2        0.64150943 0.45833333]\n",
      " [0.13793103 0.4        0.0754717  0.08333333]\n",
      " [0.34482759 0.85       0.05660377 0.125     ]\n",
      " [0.4137931  0.3        0.73584906 0.79166667]\n",
      " [0.4137931  0.4        0.66037736 0.58333333]\n",
      " [0.13793103 0.6        0.16981132 0.04166667]\n",
      " [0.         0.35       0.0754717  0.04166667]\n",
      " [0.62068966 0.3        0.71698113 0.70833333]\n",
      " [0.06896552 0.7        0.         0.04166667]\n",
      " [0.24137931 0.8        0.16981132 0.125     ]\n",
      " [0.62068966 0.35       0.62264151 0.5       ]\n",
      " [0.20689655 0.05       0.43396226 0.375     ]\n",
      " [0.20689655 0.6        0.11320755 0.125     ]\n",
      " [0.68965517 0.45       0.8490566  0.70833333]\n",
      " [0.34482759 0.4        0.66037736 0.58333333]\n",
      " [0.27586207 0.65       0.09433962 0.04166667]\n",
      " [0.5862069  0.4        0.73584906 0.70833333]\n",
      " [0.68965517 0.3        0.86792453 0.875     ]\n",
      " [0.27586207 0.25       0.54716981 0.54166667]\n",
      " [0.44827586 0.8        0.13207547 0.08333333]\n",
      " [0.55172414 0.25       0.77358491 0.625     ]]\n"
     ]
    }
   ],
   "source": [
    "#Importing the scaler to Normalize the training and testing datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Pointing the model to a variable\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#Transforming the X_Train and X_test datasets\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "#Outputting the scaled datasets for testing purpose\n",
    "print(\"X_train scaled :\", X_train_scaled)\n",
    "print(\"X_test scaled:\", X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8157894736842105\n"
     ]
    }
   ],
   "source": [
    "#Training the model with normalize data\n",
    "logreg.fit(X_train_scaled, Y_train)\n",
    "\n",
    "#Outputting scores\n",
    "print(logreg.score(X_test_scaled,  Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression did not perform better with normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try Standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fitting the model to training datasets\n",
    "scaler.fit(X_train, Y_train)\n",
    "\n",
    "#Transforming the X_train and X_test datasets\n",
    "X_train_scalled =scaler.transform(X_train)\n",
    "\n",
    "X_test_scalled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training  the model with scaled data\n",
    "logreg.fit(X_train_scalled, Y_train)\n",
    "logreg.score(X_test_scalled, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 1.         0.93333333 0.96666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Analyzing predictions score with cross_val_score \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross = cross_val_score(logreg, iris.data, iris.target, cv=5)\n",
    "print(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making predictions with KNeighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Pointing the model to a variable\n",
    "KN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#Fitting the training data\n",
    "KN.fit(X_train, Y_train)\n",
    "\n",
    "#outputting the score\n",
    "KN.score(X_test,  Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model with normalized data\n",
    "KN.fit(X_train_scaled, Y_train)\n",
    "\n",
    "#Outputting scores\n",
    "KN.score(X_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data doesn't make any difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making predictions with MLP Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
    "mlp.fit(X_train, Y_train)\n",
    "\n",
    "mlp.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.   0.98 0.98]\n"
     ]
    }
   ],
   "source": [
    "#Checking the scores with cross_val_score and Accuracy_score\n",
    "cross = cross_val_score(mlp, iris.data, iris.target, cv =3)\n",
    "print(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [112, 38]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-3756b0eeade6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \"\"\"\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [112, 38]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred =  mlp.predict(X_train)\n",
    "acc = accuracy_score(pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Random Forest Classifier to make predictions\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Rnd = RandomForestClassifier()\n",
    "Rnd.fit(X_train, Y_train)\n",
    "Rnd.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
